{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d5d8b8-816c-4067-aa41-3edad38b43bb",
   "metadata": {},
   "source": [
    "## Building A Text Summarization Model With NeMo-Run\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c48c2-d3b4-4e33-a79c-b55abd81ab31",
   "metadata": {},
   "source": [
    "The notebook content focuses on teaching learners how to fine-tune an SOTA model for a summarization task using NeMo-Run. The rest of the notebook will expose learners to the NeMo Framework, an overview of NeMo-Run, NeMo fine-tuning models, and LoRA. Upon completing this content, learners will be able to fine-tune an SOTA model for the summarization task and perform inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca32222-1cfc-4ed8-bbb7-027d4a62df1d",
   "metadata": {},
   "source": [
    "### Overview of NeMo Framework\n",
    "\n",
    "[NVIDIA NeMo Framework](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html) is a scalable and cloud-native generative AI framework built for researchers and developers working on Large Language Models, Multimodal, and Speech AI (e.g., Automatic Speech Recognition and Text-to-Speech). It provides end-to-end support for developing Large Language Models (LLMs) and provides the flexibility to be used on-premises, in a data center, or with your preferred cloud provider. It also supports execution on `SLURM` or `Kubernetes-enabled` environments. NeMo Framework provides tools for efficient training and customization of LLM models. It includes default configurations for setting up a compute cluster, downloading data, and adjusting model hyperparameters, which can be customized to train on new datasets and models. In addition to pre-training, NeMo supports both [Supervised Fine-Tuning (SFT)](https://huggingface.co/learn/llm-course/en/chapter11/3) and [Parameter-Efficient Fine-Tuning (PEFT)](https://arxiv.org/pdf/2312.12148) techniques, such as [LoRA](https://arxiv.org/pdf/2106.09685), [Ptuning](https://arxiv.org/pdf/2110.07602), and others.\n",
    "\n",
    "<center><img src=\"images/NeMo-arch.png\" width=\"900px\" height=\"900px\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c0000-e7c4-480a-a206-e38491257704",
   "metadata": {},
   "source": [
    "There are two options available for launching the training process in NeMo: using the `NeMo 2.0 API interface` or with [NeMo Run](https://github.com/NVIDIA-NeMo/Run). For this notebook, our focus will be on using `NeMo Run`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfc9be-bcc0-404c-bf63-6c44731d85b1",
   "metadata": {},
   "source": [
    "#### NeMo Supported Models for Finetuning LLM\n",
    "\n",
    "NeMo comes equipped with a CLI that allows you to launch experiments locally or on a remote cluster. Through the CLI, you can check the list of fine-tune models. Run the cell below to view the list of nemo llm finetune models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db51ac3-e39c-49cf-b06e-d69b98896afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nemo llm finetune --help llama31_8b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece26938-ebd1-43bc-b843-34c42e353182",
   "metadata": {},
   "source": [
    "```python\n",
    "...\n",
    "╭─ Pre-loaded entrypoint factories, run with --factory ────────────────────────╮\n",
    "│ baichuan2_7b               \u001b]8;id=453595;file:///opt/NeMo-Run/nemo_run/cli/api.py#L236\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                   │\n",
    "│ chatglm3_6b                \u001b]8;id=447150;file:///opt/NeMo-Run/nemo_run/cli/api.py#L236\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                   │\n",
    "│ deepseek_v2                \u001b]8;id=826757;file:///opt/NeMo-Run/nemo_run/cli/api.py#L108\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                   │\n",
    "│ deepseek_v2_lite           \u001b]8;id=169312;file:///opt/NeMo-Run/nemo_run/cli/api.py#L107\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                   │\n",
    "│ deepseek_v3                \u001b]8;id=602877;file:///opt/NeMo-Run/nemo_run/cli/api.py#L88\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                    │\n",
    "│ e5_340m                    \u001b]8;id=586107;file:///opt/NeMo-Run/nemo_run/cli/api.py#L46\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                    │\n",
    "│ gemma2_2b                  \u001b]8;id=885420;file:///opt/NeMo-Run/nemo_run/cli/api.py#L173\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                   │\n",
    "...\n",
    "│ llama3_8b                  \u001b]8;id=606922;file:///opt/NeMo-Run/nemo_run/cli/api.py#L247\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                   │\n",
    "│ llama3_70b                 \u001b]8;id=740427;file:///opt/NeMo-Run/nemo_run/cli/api.py#L251\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\                   │\n",
    "│ llama31_8b                 \u001b]8;id=231473;file:///opt/NeMo-Run/nemo_run/cli/api.py#L246\u001b\\nemo.collections.llm.r…\u001b]8;;\u001b\\          \n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d71a6-7827-4536-9ff8-a9f1866bc592",
   "metadata": {},
   "source": [
    "### Getting Started With NeMo Run \n",
    "\n",
    "NeMo Run is a powerful tool designed to streamline the configuration, execution, and management of machine learning experiments across various computing environments. NeMo Run has three core responsibilities: [Configuration](https://github.com/NVIDIA-NeMo/Run/blob/main/docs/source/guides/configuration.md), [Execution](https://github.com/NVIDIA-NeMo/Run/blob/main/docs/source/guides/execution.md), and [Management](https://github.com/NVIDIA-NeMo/Run/blob/main/docs/source/guides/management.md).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c8f2e-ac57-4548-b80f-96510308fd0c",
   "metadata": {},
   "source": [
    " #### Finetuning Custom Summarization Dataset with NeMo Run \n",
    "\n",
    "One of the main benefits of NeMo-Run is that it decouples configuration and execution, allowing the reuse of predefined executors and simply changing the recipe. [Important reasons](https://github.com/NVIDIA-NeMo/Run/blob/main/docs/source/guides/why-use-nemo-run.md) why we used NeMo Run are that it provides `Flexibility`, `Modularity`, `Reproducibility`, and `Organization`. To get started with Finetuning: \n",
    "- We need to set up your [Hugging Face token](https://huggingface.co/docs/hub/en/security-tokens) to enable the automatic conversion of the model from Hugging Face.\n",
    "- Configure the Recipe by taking 2 steps: 1) Convert the checkpoint from Hugging Face to NeMo. 2) Run fine-tuning using the converted checkpoint from step 1. We will accomplish this using a NeMo-Run experiment, which allows us to define these two tasks and execute them sequentially with ease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fbd325-4f54-4e21-99c6-ebbd4056f249",
   "metadata": {},
   "source": [
    "Log in with your token via huggingface-cli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f725e13-67ff-4f02-a44c-755f9ddd6aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `Llama3-hf` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `Llama3-hf`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token \" add token here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc835b03-f92e-4b19-9c9d-d0b3457a1287",
   "metadata": {},
   "source": [
    "To configure the Recipe, we will write a Python file (llama3_1_8b.py) to pull the Llama 3-1-8B checkpoint from Hugging Face and convert it to NeMo format via the NeMo Run experiment. First, we need to set up the NeMo cache path to store the checkpoint. By default, NeMo stores the checkpoint here: `NEMO_MODELS_CACHE=/root/.cache/nemo/models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86dc8756-4318-4de1-b81a-92813de2b98d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/model/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"NEMO_MODELS_CACHE\"] = \"/workspace/model/\"\n",
    "os.environ[\"NEMO_MODELS_CACHE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb278a-4df2-47cb-8775-41084f688a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369da628-071d-4f01-9a2d-46c139d5dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting llama3_1_8b.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile llama3_1_8b.py\n",
    "from nemo.collections import llm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    llm.import_ckpt(\n",
    "       model=llm.LlamaModel(config=llm.Llama31Config8B()),\n",
    "        source=\"hf://meta-llama/Meta-Llama-3.1-8B\",\n",
    "        overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416096b0-7408-4f0b-abf6-b424db69d37f",
   "metadata": {},
   "source": [
    "Run the script to pull the Llama 3-1-8B checkpoint from Hugging Face and convert it to NeMo format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ebe268-f847-4e04-99de-769be1ae2667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-27 19:36:14 nemo_logging:405] Please use the EncDecSpeakerLabelModel instead of this model. EncDecClassificationModel model is kept for backward compatibility with older models.\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:01<00:00,  2.35it/s]\n",
      "GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-07-27 19:36:20 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "    \n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2025-07-27 19:36:20 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "    \n",
      "[NeMo I 2025-07-27 19:36:20 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.\n",
      "[NeMo I 2025-07-27 19:36:26 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.\n",
      "[NeMo W 2025-07-27 19:36:26 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-07-27 19:36:26 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-07-27 19:36:27 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 0 : Start time: 1753644986.948s : Save duration: 0.709s\n",
      "[NeMo I 2025-07-27 19:36:37 nemo_logging:393] Successfully saved checkpoint from iteration       0 to /workspace/model/meta-llama/Meta-Llama-3.1-8B\n",
      "[NeMo I 2025-07-27 19:36:38 nemo_logging:393] Async finalization time took 10.174 s\n",
      "Converted Llama model to Nemo, model saved to /workspace/model/meta-llama/Meta-Llama-3.1-8B in torch.bfloat16.\n",
      "\u001b[32m $\u001b[0m\u001b[32mNEMO_MODELS_CACHE\u001b[0m\u001b[32m=\u001b[0m\u001b[32m/workspace/\u001b[0m\u001b[32mmodel\u001b[0m\u001b[32m \u001b[0m\n",
      "\u001b[1;34mImported Checkpoint\u001b[0m\n",
      "├── \u001b[1;36mcontext/\u001b[0m\n",
      "│   ├── \u001b[1;36martifacts/\u001b[0m\n",
      "│   │   └── \u001b[33mgeneration_config.json\u001b[0m\n",
      "│   ├── \u001b[1;36mnemo_tokenizer/\u001b[0m\n",
      "│   │   ├── \u001b[33mspecial_tokens_map.json\u001b[0m\n",
      "│   │   ├── \u001b[33mtokenizer.json\u001b[0m\n",
      "│   │   └── \u001b[33mtokenizer_config.json\u001b[0m\n",
      "│   ├── \u001b[33mio.json\u001b[0m\n",
      "│   └── \u001b[37mmodel.yaml\u001b[0m\n",
      "└── \u001b[1;36mweights/\u001b[0m\n",
      "    ├── \u001b[37m.metadata\u001b[0m\n",
      "    ├── \u001b[37m__0_0.distcp\u001b[0m\n",
      "    ├── \u001b[37m__0_1.distcp\u001b[0m\n",
      "    ├── \u001b[35mcommon.pt\u001b[0m\n",
      "    └── \u001b[33mmetadata.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!torchrun llama3_1_8b.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a99fe-034b-4bcc-bcea-9940c138df1b",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```python\n",
    "...\n",
    "\n",
    "[NeMo I 2025-07-27 19:36:37 nemo_logging:393] Successfully saved checkpoint from iteration       0 to /workspace/model/meta-llama/Meta-Llama-3.1-8B\n",
    "[NeMo I 2025-07-27 19:36:38 nemo_logging:393] Async finalization time took 10.174 s\n",
    "Converted Llama model to Nemo, model saved to /workspace/model/meta-llama/Meta-Llama-3.1-8B in torch.bfloat16.\n",
    " $NEMO_MODELS_CACHE=/workspace/model \n",
    "Imported Checkpoint\n",
    "├── context/\n",
    "│   ├── artifacts/\n",
    "│   │   └── generation_config.json\n",
    "│   ├── nemo_tokenizer/\n",
    "│   │   ├── special_tokens_map.json\n",
    "│   │   ├── tokenizer.json\n",
    "│   │   └── tokenizer_config.json\n",
    "│   ├── io.json\n",
    "│   └── model.yaml\n",
    "└── weights/\n",
    "    ├── .metadata\n",
    "    ├── __0_0.distcp\n",
    "    ├── __0_1.distcp\n",
    "    ├── common.pt\n",
    "    └── metadata.json\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aed70b-1a2c-401f-8ca4-9eedaebc1684",
   "metadata": {},
   "source": [
    "Run the functions to configure the recipe and local executor. Note that we set the PEFT scheme (peft_scheme) to LoRA. If you intend to perform a full fine-tuning, you can set it to None `(peft_scheme=None)`. [PEFT](https://arxiv.org/abs/2305.16742) allows fine-tuning a small number of (extra) model parameters instead of all the model's parameters, and this significantly decreases the computational and storage costs. One way to implement PEFT is to adopt the Low-Rank Adaptation (LoRA) technique. Lora makes fine-tuning more efficient by greatly reducing the number of trainable parameters for downstream tasks. It does this by freezing the pre-trained model weights and injecting trainable rank decomposition matrices into each layer of the Transformer architecture. According to the [authors of LoRA](https://arxiv.org/abs/2106.09685), aside from reducing the number of trainable parameters by 10k times, it also reduces the GPU consumption by 3x, thus delivering high throughput with no inference latency.\n",
    "\n",
    "<center><img src=\"images/lora-arch.png\" height=\"400px\" width=\"600px\"  /></center>\n",
    "<center> LoRA Reparametrization and Weight Merging. <a href=\"https://huggingface.co/docs/peft/main/en/conceptual_guides/lora\"> View source</a> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca918c1b-697c-468e-be3a-41ec52ea2792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-27 20:06:52 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "      from .autonotebook import tqdm as notebook_tqdm\n",
      "    \n",
      "[NeMo W 2025-07-27 20:07:00 nemo_logging:405] Please use the EncDecSpeakerLabelModel instead of this model. EncDecClassificationModel model is kept for backward compatibility with older models.\n"
     ]
    }
   ],
   "source": [
    "import nemo_run as run\n",
    "from nemo.collections import llm\n",
    "\n",
    "def configure_recipe(nodes: int = 1, gpus_per_node: int = 1):\n",
    "    recipe = llm.llama31_8b.finetune_recipe(\n",
    "        num_nodes=nodes,\n",
    "        num_gpus_per_node=gpus_per_node,\n",
    "        peft_scheme='lora',\n",
    "    )\n",
    "    return recipe\n",
    "\n",
    "def local_executor_torchrun(devices: int = 1) -> run.LocalExecutor:\n",
    "    executor = run.LocalExecutor(ntasks_per_node=devices, launcher=\"torchrun\")\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d972d-7260-4c0a-8f21-98e6b6a9d846",
   "metadata": {},
   "source": [
    "Instantiate the recipe and make sure you set the gpus_per_node as expected. In our case, we set the value to a GPU, 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f679c75-35d8-401d-b2a3-f068fc4d96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = configure_recipe(gpus_per_node=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300fe3b-8927-4ef9-bcc7-05d7775f21e8",
   "metadata": {},
   "source": [
    "##### Define Custom Data Source \n",
    "\n",
    "From the previous notebook, we preprocessed the SAMSum summarization dataset for the `FineTuningDataModule` and `ChatDataModule` objects. To use the `FineTuningDataModule` object, replace the `recipe.data` value in the cell below with the code snippet below.\n",
    "\n",
    "```python\n",
    " recipe.data = run.Config( llm.FineTuningDataModule,\n",
    "   dataset_root=\"../data/SAMSum/finetune_module/\",\n",
    "   seq_length=2048, #512,\n",
    "   micro_batch_size=1,\n",
    "   global_batch_size=32, #128\n",
    "                           )\n",
    "```\n",
    "For the fine-tuning process, we will use the ChatDataModule format for our custom preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b427cec-688d-492f-831b-e86b2297e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe.data = run.Config(\n",
    "    llm.ChatDataModule,\n",
    "    dataset_root=\"../data/SAMSum/chat_module/\",\n",
    "    seq_length=2048,\n",
    "    micro_batch_size=1,\n",
    "    global_batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc09fab-f3ad-47fc-9981-114b52f4c501",
   "metadata": {},
   "source": [
    "Setting hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d37f13-212a-4374-9cca-216b3e75b79b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment nemo.collections.llm.api.finetune with id: nemo.collections.llm.api.finetune_1753648690</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─── \u001b[0m\u001b[1;35mEntering Experiment nemo.collections.llm.api.finetune with id: nemo.collections.llm.api.finetune_1753648690\u001b[0m\u001b[92m ───\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1753648690/nemo.collections.llm.api.finetune\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:38:10] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job nemo.collections.llm.api.finetune for experiment </span>                        <a href=\"file:///opt/NeMo-Run/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/nemo_run/run/experiment.py#744\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">744</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">nemo.collections.llm.api.finetune</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:38:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job nemo.collections.llm.api.finetune for experiment \u001b[0m                        \u001b]8;id=330254;file:///opt/NeMo-Run/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=192157;file:///opt/NeMo-Run/nemo_run/run/experiment.py#744\u001b\\\u001b[2m744\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mnemo.collections.llm.api.finetune\u001b[0m                                                      \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1753648690/nemo.collections.llm.api.finetune\n",
      "Launched app: local_persistent://nemo_run/nemo.collections.llm.api.finetune-ztkbrsjbg7b76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment nemo.collections.llm.api.finetune_1753648690 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment nemo.collections.llm.api.finetune_1753648690 to finish\u001b[0m\u001b[92m ──────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.finetune_1753648690</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mnemo.collections.llm.api.finetune_1753648690\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.finetune</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: nemo.collections.llm.api.finetune-ztkbrsjbg7b76\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1753648690/nemo.collections.llm.api.finetune\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mnemo.collections.llm.api.finetune\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: nemo.collections.llm.api.finetune-ztkbrsjbg7b76\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1753648690/nemo.collections.llm.api.finetune\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job nemo.collections.llm.api.finetune-ztkbrsjbg7b76 to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.finetune/0 I0727 20:38:12.365000 7860 torch/distributed/run.py:646] Using nproc_per_node=1.\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195] Starting elastic_operator with launch configs:\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   entrypoint       : nemo_run.core.runners.fdl_runner\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   min_nodes        : 1\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   max_nodes        : 1\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   nproc_per_node   : 1\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   run_id           : 1044\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   rdzv_backend     : c10d\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   rdzv_endpoint    : localhost:0\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   rdzv_configs     : {'timeout': 900}\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   max_restarts     : 0\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   monitor_interval : 0.1\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   log_dir          : /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1753648690/nemo.collections.llm.api.finetune/nemo_run/nemo.collections.llm.api.finetune-ztkbrsjbg7b76/torchelastic/nemo.collections.llm.api.finetune\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195]   metrics_cfg      : {}\n",
      "i.finetune/0 I0727 20:38:12.366000 7860 torch/distributed/launcher/api.py:195] \n",
      "i.finetune/0 I0727 20:38:12.371000 7860 torch/distributed/elastic/agent/server/api.py:860] [default] starting workers for entrypoint: python\n",
      "i.finetune/0 I0727 20:38:12.372000 7860 torch/distributed/elastic/agent/server/api.py:677] [default] Rendezvous'ing worker group\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   restart_count=0\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   master_addr=26ab9a6e7f8a\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   master_port=36879\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   group_rank=0\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   group_world_size=1\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0]\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0]\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0]\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[1]\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[1]\n",
      "i.finetune/0 I0727 20:38:12.586000 7860 torch/distributed/elastic/agent/server/api.py:525] \n",
      "i.finetune/0 I0727 20:38:12.587000 7860 torch/distributed/elastic/agent/server/api.py:685] [default] Starting worker group\n",
      "i.finetune/0 I0727 20:38:12.588000 7860 torch/distributed/elastic/agent/server/local_elastic_agent.py:298] use_agent_store: True\n",
      "i.finetune/0 I0727 20:38:12.588000 7860 torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "i.finetune/0 I0727 20:38:12.589000 7860 torch/distributed/elastic/agent/server/local_elastic_agent.py:236] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.\n",
      "i.finetune/0 [default0]:[NeMo W 2025-07-27 20:38:27 nemo_logging:405] Please use the EncDecSpeakerLabelModel instead of this model. EncDecClassificationModel model is kept for backward compatibility with older models.\n",
      "i.finetune/0 [default0]:GPU available: True (cuda), used: True\n",
      "i.finetune/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "i.finetune/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Disabling try_restore_best_ckpt restoration for adapters\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Experiments will be logged at /workspace/lab_finetuning_log\n",
      "i.finetune/0 [default0]:[NeMo W 2025-07-27 20:38:28 nemo_logging:405] NeMoLogger is logging to /workspace/lab_finetuning_log, but it already exists.\n",
      "i.finetune/0 [default0]:[NeMo W 2025-07-27 20:38:28 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /workspace/lab_finetuning_log/tb_logs\n",
      "i.finetune/0 [default0]:[NeMo W 2025-07-27 20:38:28 nemo_logging:405] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "i.finetune/0 [default0]:[NeMo W 2025-07-27 20:38:28 nemo_logging:405] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 100. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:28 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "i.finetune/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "i.finetune/0 [default0]:distributed_backend=nccl\n",
      "i.finetune/0 [default0]:All distributed processes registered. Starting with 1 processes\n",
      "i.finetune/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "i.finetune/0 [default0]:\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Setting up ModelTransform for stage: TrainerFn.FITTING\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Found model_transform attribute on pl_module\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Set model_transform to: <function _call_counter.<locals>.wrapper at 0x7ffbcb10f4c0>\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Copying Trainer's 'max_steps' (100) to LR scheduler's 'max_steps'.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Doing selective restore from RestoreConfig(path='/workspace/model/meta-llama/Meta-Llama-3.1-8B', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:29 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x7ffa67152cf0> dist-ckpt load strategy.\n",
      "i.finetune/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:37 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1753648709.847s : Time spent in load_checkpoint: 7.417s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:37 nemo_logging:393] Restoring model weights from RestoreConfig(path='/workspace/model/meta-llama/Meta-Llama-3.1-8B', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:37 nemo_logging:393] Finished restoring from RestoreConfig(path='/workspace/model/meta-llama/Meta-Llama-3.1-8B', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "i.finetune/0 [default0]:\n",
      "i.finetune/0 [default0]:  | Name   | Type     | Params | Mode \n",
      "i.finetune/0 [default0]:--------------------------------------------\n",
      "i.finetune/0 [default0]:0 | module | GPTModel | 8.0 B  | train\n",
      "i.finetune/0 [default0]:--------------------------------------------\n",
      "i.finetune/0 [default0]:8.0 B     Trainable params\n",
      "i.finetune/0 [default0]:0         Non-trainable params\n",
      "i.finetune/0 [default0]:8.0 B     Total params\n",
      "i.finetune/0 [default0]:32,121.045Total estimated model params size (MB)\n",
      "i.finetune/0 [default0]:649       Modules in train mode\n",
      "i.finetune/0 [default0]:0         Modules in eval mode\n",
      "i.finetune/0 [default0]:[rank: 0] Received SIGTERM: 15\n",
      "i.finetune/0 [default0]:[rank: 0] Received SIGTERM: 15\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.0.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.0.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.0.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.0.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.1.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.1.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.1.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.1.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.2.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.2.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.2.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.2.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.3.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.3.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.3.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.3.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.4.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.4.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.4.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.4.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.5.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.5.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.5.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.5.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.6.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.6.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.6.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.6.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.7.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.7.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.7.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.7.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.8.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.8.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.8.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.8.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.9.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.9.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.9.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.9.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.10.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.10.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.10.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.10.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.11.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.11.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.11.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.11.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.12.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.12.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.12.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.12.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.13.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.13.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.13.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.13.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.14.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.14.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.14.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.14.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.15.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.15.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.15.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.15.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.16.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.16.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.16.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.16.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.17.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.17.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.17.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.17.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.18.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.18.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.18.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.18.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.19.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.19.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.19.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.19.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.20.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.20.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.20.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.20.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.21.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.21.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.21.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.21.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.22.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.22.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.22.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.22.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.23.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.23.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.23.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.23.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.24.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.24.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.24.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.24.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.25.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.25.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.25.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.25.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.26.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.26.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.26.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.26.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.27.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.27.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.27.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.27.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.28.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.28.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.28.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.28.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.29.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.29.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.29.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.29.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.30.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.30.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.30.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.30.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.31.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.31.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.31.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Adding lora to: module.decoder.layers.31.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] After applying model_transform:\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:  | Name   | Type     | Params | Mode \n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:--------------------------------------------\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:0 | module | GPTModel | 8.0 B  | train\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:--------------------------------------------\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:17.8 M    Trainable params\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:8.0 B     Non-trainable params\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:8.0 B     Total params\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:32,192.348Total estimated model params size (MB)\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:1289      Modules in train mode\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:0         Modules in eval mode\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Initializing model parallel\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8048087040\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393]  > number of trainable parameters: 17825792 (0.22% of total)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 utils:507] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=400000000, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 utils:528] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "i.finetune/0 [default0]:    Params for bucket 1 (17825792 elements, 17825792 padded size):\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 nemo_logging:393] Setting up optimizers\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:38:38 utils:507] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.98, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "i.finetune/0 [default0]:[NeMo W 2025-07-27 20:38:48 rerun_state_machine:1264] Implicit initialization of Rerun State Machine!\n",
      "i.finetune/0 [default0]:[NeMo W 2025-07-27 20:38:48 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 0/99 | lr: 1.961e-06 | global_batch_size: 32 | global_step: 0 | reduced_train_loss: 1.564 | train_step_timing in s: 10.28\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 1/99 | lr: 3.922e-06 | global_batch_size: 32 | global_step: 1 | reduced_train_loss: 1.665 | train_step_timing in s: 7.658 | consumed_samples: 64\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 2/99 | lr: 5.882e-06 | global_batch_size: 32 | global_step: 2 | reduced_train_loss: 1.621 | train_step_timing in s: 6.52 | consumed_samples: 96\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 3/99 | lr: 7.843e-06 | global_batch_size: 32 | global_step: 3 | reduced_train_loss: 1.576 | train_step_timing in s: 6.144 | consumed_samples: 128\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 4/99 | lr: 9.804e-06 | global_batch_size: 32 | global_step: 4 | reduced_train_loss: 1.56 | train_step_timing in s: 6.176 | consumed_samples: 160\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 5/99 | lr: 1.176e-05 | global_batch_size: 32 | global_step: 5 | reduced_train_loss: 1.644 | train_step_timing in s: 6.168 | consumed_samples: 192\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 6/99 | lr: 1.373e-05 | global_batch_size: 32 | global_step: 6 | reduced_train_loss: 1.6 | train_step_timing in s: 6.141 | consumed_samples: 224\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 7/99 | lr: 1.569e-05 | global_batch_size: 32 | global_step: 7 | reduced_train_loss: 1.547 | train_step_timing in s: 6.147 | consumed_samples: 256\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 8/99 | lr: 1.765e-05 | global_batch_size: 32 | global_step: 8 | reduced_train_loss: 1.482 | train_step_timing in s: 6.497 | consumed_samples: 288\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 9/99 | lr: 1.961e-05 | global_batch_size: 32 | global_step: 9 | reduced_train_loss: 1.413 | train_step_timing in s: 6.166 | consumed_samples: 320\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 10/99 | lr: 2.157e-05 | global_batch_size: 32 | global_step: 10 | reduced_train_loss: 1.429 | train_step_timing in s: 6.148 | consumed_samples: 352\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 11/99 | lr: 2.353e-05 | global_batch_size: 32 | global_step: 11 | reduced_train_loss: 1.298 | train_step_timing in s: 6.228 | consumed_samples: 384\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 12/99 | lr: 2.549e-05 | global_batch_size: 32 | global_step: 12 | reduced_train_loss: 1.294 | train_step_timing in s: 6.212 | consumed_samples: 416\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 13/99 | lr: 2.745e-05 | global_batch_size: 32 | global_step: 13 | reduced_train_loss: 1.245 | train_step_timing in s: 6.551 | consumed_samples: 448\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 14/99 | lr: 2.941e-05 | global_batch_size: 32 | global_step: 14 | reduced_train_loss: 1.157 | train_step_timing in s: 6.091 | consumed_samples: 480\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 15/99 | lr: 3.137e-05 | global_batch_size: 32 | global_step: 15 | reduced_train_loss: 1.22 | train_step_timing in s: 6.092 | consumed_samples: 512\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 16/99 | lr: 3.333e-05 | global_batch_size: 32 | global_step: 16 | reduced_train_loss: 1.063 | train_step_timing in s: 6.155 | consumed_samples: 544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 17/99 | lr: 3.529e-05 | global_batch_size: 32 | global_step: 17 | reduced_train_loss: 1.03 | train_step_timing in s: 6.124 | consumed_samples: 576\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 18/99 | lr: 3.725e-05 | global_batch_size: 32 | global_step: 18 | reduced_train_loss: 1.043 | train_step_timing in s: 6.142 | consumed_samples: 608\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 19/99 | lr: 3.922e-05 | global_batch_size: 32 | global_step: 19 | reduced_train_loss: 1.081 | train_step_timing in s: 6.575 | consumed_samples: 640\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 20/99 | lr: 4.118e-05 | global_batch_size: 32 | global_step: 20 | reduced_train_loss: 0.9383 | train_step_timing in s: 6.147 | consumed_samples: 672\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 21/99 | lr: 4.314e-05 | global_batch_size: 32 | global_step: 21 | reduced_train_loss: 1.019 | train_step_timing in s: 6.139 | consumed_samples: 704\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 22/99 | lr: 4.51e-05 | global_batch_size: 32 | global_step: 22 | reduced_train_loss: 0.9974 | train_step_timing in s: 6.115 | consumed_samples: 736\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 23/99 | lr: 4.706e-05 | global_batch_size: 32 | global_step: 23 | reduced_train_loss: 1.037 | train_step_timing in s: 6.133 | consumed_samples: 768\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 24/99 | lr: 4.902e-05 | global_batch_size: 32 | global_step: 24 | reduced_train_loss: 0.8617 | train_step_timing in s: 6.211 | consumed_samples: 800\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 25/99 | lr: 5.098e-05 | global_batch_size: 32 | global_step: 25 | reduced_train_loss: 0.961 | train_step_timing in s: 6.515 | consumed_samples: 832\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 26/99 | lr: 5.294e-05 | global_batch_size: 32 | global_step: 26 | reduced_train_loss: 0.8736 | train_step_timing in s: 6.163 | consumed_samples: 864\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 27/99 | lr: 5.49e-05 | global_batch_size: 32 | global_step: 27 | reduced_train_loss: 0.8228 | train_step_timing in s: 6.167 | consumed_samples: 896\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 28/99 | lr: 5.686e-05 | global_batch_size: 32 | global_step: 28 | reduced_train_loss: 0.8404 | train_step_timing in s: 6.152 | consumed_samples: 928\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 29/99 | lr: 5.882e-05 | global_batch_size: 32 | global_step: 29 | reduced_train_loss: 0.8842 | train_step_timing in s: 6.133 | consumed_samples: 960\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 30/99 | lr: 6.078e-05 | global_batch_size: 32 | global_step: 30 | reduced_train_loss: 0.8506 | train_step_timing in s: 6.49 | consumed_samples: 992\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 31/99 | lr: 6.275e-05 | global_batch_size: 32 | global_step: 31 | reduced_train_loss: 1.068 | train_step_timing in s: 6.113 | consumed_samples: 1024\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 32/99 | lr: 6.471e-05 | global_batch_size: 32 | global_step: 32 | reduced_train_loss: 1.053 | train_step_timing in s: 6.099 | consumed_samples: 1056\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 33/99 | lr: 6.667e-05 | global_batch_size: 32 | global_step: 33 | reduced_train_loss: 0.9837 | train_step_timing in s: 6.187 | consumed_samples: 1088\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 34/99 | lr: 6.863e-05 | global_batch_size: 32 | global_step: 34 | reduced_train_loss: 0.957 | train_step_timing in s: 6.169 | consumed_samples: 1120\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 35/99 | lr: 7.059e-05 | global_batch_size: 32 | global_step: 35 | reduced_train_loss: 0.879 | train_step_timing in s: 6.161 | consumed_samples: 1152\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 36/99 | lr: 7.255e-05 | global_batch_size: 32 | global_step: 36 | reduced_train_loss: 1.004 | train_step_timing in s: 6.522 | consumed_samples: 1184\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 37/99 | lr: 7.451e-05 | global_batch_size: 32 | global_step: 37 | reduced_train_loss: 0.7754 | train_step_timing in s: 6.129 | consumed_samples: 1216\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 38/99 | lr: 7.647e-05 | global_batch_size: 32 | global_step: 38 | reduced_train_loss: 0.8689 | train_step_timing in s: 6.158 | consumed_samples: 1248\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 39/99 | lr: 7.843e-05 | global_batch_size: 32 | global_step: 39 | reduced_train_loss: 0.7821 | train_step_timing in s: 6.134 | consumed_samples: 1280\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 40/99 | lr: 8.039e-05 | global_batch_size: 32 | global_step: 40 | reduced_train_loss: 0.845 | train_step_timing in s: 6.164 | consumed_samples: 1312\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 41/99 | lr: 8.235e-05 | global_batch_size: 32 | global_step: 41 | reduced_train_loss: 0.8815 | train_step_timing in s: 6.557 | consumed_samples: 1344\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 42/99 | lr: 8.431e-05 | global_batch_size: 32 | global_step: 42 | reduced_train_loss: 0.7776 | train_step_timing in s: 6.176 | consumed_samples: 1376\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 43/99 | lr: 8.627e-05 | global_batch_size: 32 | global_step: 43 | reduced_train_loss: 0.6919 | train_step_timing in s: 6.111 | consumed_samples: 1408\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 44/99 | lr: 8.824e-05 | global_batch_size: 32 | global_step: 44 | reduced_train_loss: 0.7477 | train_step_timing in s: 6.145 | consumed_samples: 1440\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 45/99 | lr: 9.02e-05 | global_batch_size: 32 | global_step: 45 | reduced_train_loss: 0.8281 | train_step_timing in s: 6.13 | consumed_samples: 1472\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 46/99 | lr: 9.216e-05 | global_batch_size: 32 | global_step: 46 | reduced_train_loss: 0.9094 | train_step_timing in s: 6.19 | consumed_samples: 1504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 47/99 | lr: 9.412e-05 | global_batch_size: 32 | global_step: 47 | reduced_train_loss: 0.8599 | train_step_timing in s: 6.504 | consumed_samples: 1536\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 48/99 | lr: 9.608e-05 | global_batch_size: 32 | global_step: 48 | reduced_train_loss: 0.8164 | train_step_timing in s: 6.178 | consumed_samples: 1568\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 49/99 | lr: 9.804e-05 | global_batch_size: 32 | global_step: 49 | reduced_train_loss: 0.8424 | train_step_timing in s: 6.147 | consumed_samples: 1600\n",
      "i.finetune/0 [default0]:Epoch 0, global step 49: 'val_loss' was not in top 2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:43:55 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:43:55 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 49 : Start time: 1753649035.692s : Save duration: 0.266s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:43:56 nemo_logging:393] Scheduled async checkpoint save for /workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=49-consumed_samples=1600.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:43:56 nemo_logging:393] Async finalization time took 0.002 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 50/99 | lr: 0.0001 | global_batch_size: 32 | global_step: 50 | reduced_train_loss: 0.8627 | train_step_timing in s: 6.099 | consumed_samples: 1632\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:44:02 nemo_logging:393] Successfully saved checkpoint from iteration      49 to /workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=49-consumed_samples=1600.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:44:02 nemo_logging:393] Async checkpoint save for step 50 (/workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=49-consumed_samples=1600.0-last.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:44:02 nemo_logging:393] Async finalization time took 0.051 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 51/99 | lr: 9.99e-05 | global_batch_size: 32 | global_step: 51 | reduced_train_loss: 0.929 | train_step_timing in s: 6.667 | consumed_samples: 1664\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 52/99 | lr: 9.961e-05 | global_batch_size: 32 | global_step: 52 | reduced_train_loss: 0.7825 | train_step_timing in s: 6.187 | consumed_samples: 1696\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 53/99 | lr: 9.911e-05 | global_batch_size: 32 | global_step: 53 | reduced_train_loss: 0.9483 | train_step_timing in s: 6.14 | consumed_samples: 1728\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 54/99 | lr: 9.843e-05 | global_batch_size: 32 | global_step: 54 | reduced_train_loss: 0.8354 | train_step_timing in s: 6.153 | consumed_samples: 1760\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 55/99 | lr: 9.755e-05 | global_batch_size: 32 | global_step: 55 | reduced_train_loss: 0.8877 | train_step_timing in s: 6.142 | consumed_samples: 1792\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 56/99 | lr: 9.649e-05 | global_batch_size: 32 | global_step: 56 | reduced_train_loss: 0.9184 | train_step_timing in s: 6.112 | consumed_samples: 1824\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 57/99 | lr: 9.524e-05 | global_batch_size: 32 | global_step: 57 | reduced_train_loss: 0.845 | train_step_timing in s: 6.568 | consumed_samples: 1856\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 58/99 | lr: 9.382e-05 | global_batch_size: 32 | global_step: 58 | reduced_train_loss: 0.9348 | train_step_timing in s: 6.254 | consumed_samples: 1888\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 59/99 | lr: 9.222e-05 | global_batch_size: 32 | global_step: 59 | reduced_train_loss: 0.8918 | train_step_timing in s: 6.165 | consumed_samples: 1920\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 60/99 | lr: 9.045e-05 | global_batch_size: 32 | global_step: 60 | reduced_train_loss: 0.8439 | train_step_timing in s: 6.075 | consumed_samples: 1952\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 61/99 | lr: 8.853e-05 | global_batch_size: 32 | global_step: 61 | reduced_train_loss: 0.8224 | train_step_timing in s: 6.033 | consumed_samples: 1984\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 62/99 | lr: 8.645e-05 | global_batch_size: 32 | global_step: 62 | reduced_train_loss: 0.8533 | train_step_timing in s: 6.455 | consumed_samples: 2016\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 63/99 | lr: 8.423e-05 | global_batch_size: 32 | global_step: 63 | reduced_train_loss: 0.909 | train_step_timing in s: 6.052 | consumed_samples: 2048\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 64/99 | lr: 8.187e-05 | global_batch_size: 32 | global_step: 64 | reduced_train_loss: 0.8325 | train_step_timing in s: 6.068 | consumed_samples: 2080\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 65/99 | lr: 7.939e-05 | global_batch_size: 32 | global_step: 65 | reduced_train_loss: 0.845 | train_step_timing in s: 6.167 | consumed_samples: 2112\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 66/99 | lr: 7.679e-05 | global_batch_size: 32 | global_step: 66 | reduced_train_loss: 0.8008 | train_step_timing in s: 6.151 | consumed_samples: 2144\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 67/99 | lr: 7.409e-05 | global_batch_size: 32 | global_step: 67 | reduced_train_loss: 0.7776 | train_step_timing in s: 6.145 | consumed_samples: 2176\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 68/99 | lr: 7.129e-05 | global_batch_size: 32 | global_step: 68 | reduced_train_loss: 0.9138 | train_step_timing in s: 6.583 | consumed_samples: 2208\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 69/99 | lr: 6.841e-05 | global_batch_size: 32 | global_step: 69 | reduced_train_loss: 0.7539 | train_step_timing in s: 6.095 | consumed_samples: 2240\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 70/99 | lr: 6.545e-05 | global_batch_size: 32 | global_step: 70 | reduced_train_loss: 0.767 | train_step_timing in s: 6.016 | consumed_samples: 2272\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 71/99 | lr: 6.243e-05 | global_batch_size: 32 | global_step: 71 | reduced_train_loss: 0.757 | train_step_timing in s: 6.075 | consumed_samples: 2304\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 72/99 | lr: 5.937e-05 | global_batch_size: 32 | global_step: 72 | reduced_train_loss: 0.7469 | train_step_timing in s: 6.051 | consumed_samples: 2336\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 73/99 | lr: 5.627e-05 | global_batch_size: 32 | global_step: 73 | reduced_train_loss: 0.7311 | train_step_timing in s: 6.042 | consumed_samples: 2368\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 74/99 | lr: 5.314e-05 | global_batch_size: 32 | global_step: 74 | reduced_train_loss: 0.7519 | train_step_timing in s: 6.439 | consumed_samples: 2400\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 75/99 | lr: 5e-05 | global_batch_size: 32 | global_step: 75 | reduced_train_loss: 0.8219 | train_step_timing in s: 6.068 | consumed_samples: 2432\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 76/99 | lr: 4.686e-05 | global_batch_size: 32 | global_step: 76 | reduced_train_loss: 0.7291 | train_step_timing in s: 6.192 | consumed_samples: 2464\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 77/99 | lr: 4.373e-05 | global_batch_size: 32 | global_step: 77 | reduced_train_loss: 0.6525 | train_step_timing in s: 6.164 | consumed_samples: 2496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 78/99 | lr: 4.063e-05 | global_batch_size: 32 | global_step: 78 | reduced_train_loss: 0.7272 | train_step_timing in s: 6.143 | consumed_samples: 2528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 79/99 | lr: 3.757e-05 | global_batch_size: 32 | global_step: 79 | reduced_train_loss: 0.7155 | train_step_timing in s: 6.539 | consumed_samples: 2560\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 80/99 | lr: 3.455e-05 | global_batch_size: 32 | global_step: 80 | reduced_train_loss: 0.6705 | train_step_timing in s: 6.097 | consumed_samples: 2592\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 81/99 | lr: 3.159e-05 | global_batch_size: 32 | global_step: 81 | reduced_train_loss: 0.8021 | train_step_timing in s: 6.108 | consumed_samples: 2624\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 82/99 | lr: 2.871e-05 | global_batch_size: 32 | global_step: 82 | reduced_train_loss: 0.7566 | train_step_timing in s: 6.086 | consumed_samples: 2656\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 83/99 | lr: 2.591e-05 | global_batch_size: 32 | global_step: 83 | reduced_train_loss: 0.7277 | train_step_timing in s: 6.061 | consumed_samples: 2688\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 84/99 | lr: 2.321e-05 | global_batch_size: 32 | global_step: 84 | reduced_train_loss: 0.7102 | train_step_timing in s: 6.083 | consumed_samples: 2720\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 85/99 | lr: 2.061e-05 | global_batch_size: 32 | global_step: 85 | reduced_train_loss: 0.6897 | train_step_timing in s: 6.488 | consumed_samples: 2752\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 86/99 | lr: 1.813e-05 | global_batch_size: 32 | global_step: 86 | reduced_train_loss: 0.682 | train_step_timing in s: 6.031 | consumed_samples: 2784\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 87/99 | lr: 1.577e-05 | global_batch_size: 32 | global_step: 87 | reduced_train_loss: 0.6394 | train_step_timing in s: 6.058 | consumed_samples: 2816\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 88/99 | lr: 1.355e-05 | global_batch_size: 32 | global_step: 88 | reduced_train_loss: 0.6551 | train_step_timing in s: 6.049 | consumed_samples: 2848\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 89/99 | lr: 1.147e-05 | global_batch_size: 32 | global_step: 89 | reduced_train_loss: 0.7257 | train_step_timing in s: 6.107 | consumed_samples: 2880\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 90/99 | lr: 9.549e-06 | global_batch_size: 32 | global_step: 90 | reduced_train_loss: 0.6228 | train_step_timing in s: 6.066 | consumed_samples: 2912\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 91/99 | lr: 7.784e-06 | global_batch_size: 32 | global_step: 91 | reduced_train_loss: 0.7224 | train_step_timing in s: 6.433 | consumed_samples: 2944\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 92/99 | lr: 6.185e-06 | global_batch_size: 32 | global_step: 92 | reduced_train_loss: 0.6396 | train_step_timing in s: 6.063 | consumed_samples: 2976\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 93/99 | lr: 4.759e-06 | global_batch_size: 32 | global_step: 93 | reduced_train_loss: 0.7043 | train_step_timing in s: 6.049 | consumed_samples: 3008\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 94/99 | lr: 3.511e-06 | global_batch_size: 32 | global_step: 94 | reduced_train_loss: 0.7127 | train_step_timing in s: 6.042 | consumed_samples: 3040\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 95/99 | lr: 2.447e-06 | global_batch_size: 32 | global_step: 95 | reduced_train_loss: 0.8096 | train_step_timing in s: 6.059 | consumed_samples: 3072\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 96/99 | lr: 1.571e-06 | global_batch_size: 32 | global_step: 96 | reduced_train_loss: 0.6341 | train_step_timing in s: 6.44 | consumed_samples: 3104\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 97/99 | lr: 8.856e-07 | global_batch_size: 32 | global_step: 97 | reduced_train_loss: 0.7896 | train_step_timing in s: 6.057 | consumed_samples: 3136\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 98/99 | lr: 3.943e-07 | global_batch_size: 32 | global_step: 98 | reduced_train_loss: 0.8339 | train_step_timing in s: 6.056 | consumed_samples: 3168\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 99/99 | lr: 9.866e-08 | global_batch_size: 32 | global_step: 99 | reduced_train_loss: 0.6286 | train_step_timing in s: 6.054 | consumed_samples: 3200\n",
      "i.finetune/0 [default0]:Epoch 0, global step 99: 'val_loss' was not in top 2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1753649345.102s : Save duration: 0.072s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Scheduled async checkpoint save for /workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=99-consumed_samples=3200.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Async finalization time took 0.001 s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Async finalization time took 0.000 s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Pending async checkpoint saves. Finalizing them synchronously now\n",
      "i.finetune/0 [default0]:`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=99-consumed_samples=3200.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Async checkpoint save for step 100 (/workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=99-consumed_samples=3200.0-last.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Async finalization time took 0.256 s\n",
      "i.finetune/0 I0727 20:49:17.888000 7860 torch/distributed/elastic/agent/server/api.py:879] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "i.finetune/0 I0727 20:49:17.889000 7860 torch/distributed/elastic/agent/server/api.py:932] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "i.finetune/0 I0727 20:49:17.890000 7860 torch/distributed/elastic/agent/server/api.py:946] Done waiting for other agents. Elapsed: 0.00012350082397460938 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job nemo.collections.llm.api.finetune-ztkbrsjbg7b76 finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['nemo.collections.llm.api.finetune']</span><span style=\"background-color: #272822\">                           </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.finetune_1753648690\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.finetune\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.finetune\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['nemo.collections.llm.api.finetune']\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.finetune_1753648690\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.finetune\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.finetune\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status nemo.collections.llm.api.finetune_1753648690</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs nemo.collections.llm.api.finetune_1753648690 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel nemo.collections.llm.api.finetune_1753648690 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                              </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.finetune_1753648690\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.finetune_1753648690\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.finetune_1753648690\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recipe.trainer.num_sanity_val_steps = 0\n",
    "\n",
    "# Need to set this to 1 since the default is 2\n",
    "recipe.trainer.strategy.context_parallel_size = 1\n",
    "recipe.trainer.val_check_interval = 100 #0\n",
    "\n",
    "recipe.trainer.limit_val_batches = 0\n",
    "recipe.trainer.max_steps = 100 #40\n",
    "recipe.log.use_datetime_version = False\n",
    "recipe.log.explicit_log_dir = '/workspace/lab_finetuning_log'\n",
    "recipe.resume.restore_config.path = '/workspace/model/meta-llama/Meta-Llama-3.1-8B/'\n",
    "# adjust other hyperparameters as needed\n",
    "# for example:\n",
    "# recipe.optim.config.lr = 1e-6\n",
    "# recipe.trainer.strategy.tensor_model_parallel_size = 2\n",
    "# recipe.log.ckpt.save_top_k = 3\n",
    "\n",
    "executor = local_executor_torchrun(devices=recipe.trainer.devices)\n",
    "run.run(recipe, executor=executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14475ad8-c012-440b-bfa9-2a48e292b13f",
   "metadata": {},
   "source": [
    "**Likely Output:**\n",
    "```python\n",
    "...\n",
    "\n",
    "Task 0: nemo.collections.llm.api.finetune\n",
    "- Status: RUNNING\n",
    "- Executor: LocalExecutor\n",
    "- Job id: nemo.collections.llm.api.finetune-ztkbrsjbg7b76\n",
    "- Local Directory: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1753648690/nemo.collecti\n",
    "...\n",
    "\n",
    "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=99-consumed_samples=3200.0-last.ckpt\n",
    "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Async checkpoint save for step 100 (/workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=99-consumed_samples=3200.0-last.ckpt) finalized successfully.\n",
    "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Async finalization time took 0.256 s\n",
    "i.finetune/0 I0727 20:49:17.888000 7860 torch/distributed/elastic/agent/server/api.py:879] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
    "i.finetune/0 I0727 20:49:17.889000 7860 torch/distributed/elastic/agent/server/api.py:932] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
    "i.finetune/0 I0727 20:49:17.890000 7860 torch/distributed/elastic/agent/server/api.py:946] Done waiting for other agents. Elapsed: 0.00012350082397460938 seconds\n",
    "Job nemo.collections.llm.api.finetune-ztkbrsjbg7b76 finished: SUCCEEDED\n",
    "```\n",
    "<center><img src=\"images/train_output.png\" width=\"700px\" height=\"700px\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e38f93-8878-4cbc-b2ac-e575ee1f80e5",
   "metadata": {},
   "source": [
    "### Running Inference\n",
    "\n",
    "After successfully training our Llama-3-1-8b checkpoint, we should evaluate the effectiveness of the fine-tuned model. First, as a sanity check, we can quickly evaluate the trained model's performance using NeMo's in-framework inference. To sart with, we need to know the path where adapter checkpoint is saved from the training log:\n",
    "\n",
    "```python\n",
    "...\n",
    "i.finetune/0 [default0]:[NeMo I 2025-07-27 20:49:05 nemo_logging:393] Async checkpoint save for step 100 (/workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=99-consumed_samples=3200.0-last.ckpt) finalized successfully.\n",
    "\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71b3d5fc-ad40-4a9d-92ba-e1e64108344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"system\": \"\", \"mask\": \"User\", \"conversations\": [{\"from\": \"User\", \"value\": \"### Instruction: Write a summary of the conversation below. ### Input: Amanda: I baked cookies. Do you want some?\\nJerry: Sure!\"}, {\"from\": \"Response\", \"value\": \"Amanda baked cookies and will bring Jerry some tomorrow.\"}]}\n",
      "{\"system\": \"\", \"mask\": \"User\", \"conversations\": [{\"from\": \"User\", \"value\": \"### Instruction: Write a summary of the conversation below. ### Input: Olivia: Who are you voting for in this election?\\nOliver: Liberals as always.\\nOlivia: Me too!!\\nOliver: Great\"}, {\"from\": \"Response\", \"value\": \"Olivia and Olivier are voting for liberals in this election.\"}]}\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../data/SAMSum/chat_module/training.jsonl > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48696cc5-55ed-48f0-9c07-37137a02b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [{\"system\": \"\", \"mask\": \"User\", \"conversations\": [{\"from\": \"User\", \"value\": \"### Instruction: Write a summary of the conversation below. ### Input: Will: hey babe, what do you want for dinner tonight?\\nEmma: gah, don't even worry about it tonight\\nWill: what do you mean? everything ok?\\nEmma: not really, but it's ok, don't worry about cooking though, I'm not hungry\\nWill: Well what time will you be home?\\nEmma: soon, hopefully\\nWill: you sure? Maybe you want me to pick you up?\\nEmma: no no it's alright. I'll be home soon, i'll tell you when I get home.\\nWill: Alright, love you.\\nEmma: love you too.\"}, {\"from\": \"Response\", \"value\": \"\"}]},\n",
    "{\"system\": \"\", \"mask\": \"User\", \"conversations\": [{\"from\": \"User\", \"value\": \"### Instruction: Write a summary of the conversation below. ### Input: Ollie: Hi , are you in Warsaw\\nJane: yes, just back! Btw are you free for diner the 19th?\\nOllie: nope!\\nJane: and the 18th?\\nOllie: nope, we have this party and you must be there, remember?\\nJane: oh right! i lost my calendar.. thanks for reminding me\\nOllie: we have lunch this week?\\nJane: with pleasure!\\nOllie: friday?\\nJane: ok\\nJane: what do you mean \\\" we don't have any more whisky!\\\" lol..\\nOllie: what!!!\\nJane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\\nOllie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\\nJane: dont' worry, we'll check on friday.\\nOllie: don't forget to bring some sun with you\\nJane: I can't wait to be in Morocco..\\nOllie: enjoy and see you friday\\nJane: sorry Ollie, i'm very busy, i won't have time for lunch tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\\nOllie: ok for tea!\\nJane: I'm on my way..\\nOllie: tea is ready, did you bring the pastries?\\nJane: I already ate them all... see you in a minute\\nOllie: ok\"}, {\"from\": \"Response\", \"value\": \"\"}]}\n",
    " ]\n",
    "groundtruth = [\n",
    "     {\"from\": \"Response\", \"value\": \"Emma will be home soon and she will let Will know.\"},\n",
    " {\"from\": \"Response\", \"value\": \"Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9491011c-a5a9-4118-821f-ef2db6e4884c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': '',\n",
       " 'mask': 'User',\n",
       " 'conversations': [{'from': 'User',\n",
       "   'value': \"### Instruction: Write a summary of the conversation below. ### Input: Will: hey babe, what do you want for dinner tonight?\\nEmma: gah, don't even worry about it tonight\\nWill: what do you mean? everything ok?\\nEmma: not really, but it's ok, don't worry about cooking though, I'm not hungry\\nWill: Well what time will you be home?\\nEmma: soon, hopefully\\nWill: you sure? Maybe you want me to pick you up?\\nEmma: no no it's alright. I'll be home soon, i'll tell you when I get home.\\nWill: Alright, love you.\\nEmma: love you too.\"},\n",
       "  {'from': 'Response', 'value': ''}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656bbc3c-52fe-4218-9a40-c514d7357103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d06c98cc-2182-483e-92fd-8ee12878e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_inference.py\n",
    "\n",
    "from megatron.core.inference.common_inference_params import CommonInferenceParams\n",
    "import nemo.lightning as nl\n",
    "from nemo.collections.llm import api\n",
    "import torch\n",
    "\n",
    "strategy = nl.MegatronStrategy(\n",
    "    tensor_model_parallel_size=1,\n",
    "    pipeline_model_parallel_size=1,\n",
    "    context_parallel_size=1,\n",
    "    sequence_parallel=False,\n",
    "    setup_optimizers=False,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = nl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    num_nodes=1,\n",
    "    strategy=strategy,\n",
    "    plugins=nl.MegatronMixedPrecision(\n",
    "        precision=\"bf16-mixed\",\n",
    "        params_dtype=torch.bfloat16,\n",
    "        pipeline_dtype=torch.bfloat16,\n",
    "    ),\n",
    ")\n",
    "\n",
    "prompts1 = [ \"### Instruction: Write a summary of the conversation below. ### Input: Will: hey babe, what do you want for dinner tonight?\\nEmma: gah, don't even worry about it tonight\\nWill: what do you mean? everything ok?\\nEmma: not really, but it's ok, don't worry about cooking though, I'm not hungry\\nWill: Well what time will you be home?\\nEmma: soon, hopefully\\nWill: you sure? Maybe you want me to pick you up?\\nEmma: no no it's alright. I'll be home soon, i'll tell you when I get home.\\nWill: Alright, love you.\\nEmma: love you too.\",\n",
    "\"### Instruction: Write a summary of the conversation below. ### Input: Ollie: Hi , are you in Warsaw\\nJane: yes, just back! Btw are you free for diner the 19th?\\nOllie: nope!\\nJane: and the 18th?\\nOllie: nope, we have this party and you must be there, remember?\\nJane: oh right! i lost my calendar.. thanks for reminding me\\nOllie: we have lunch this week?\\nJane: with pleasure!\\nOllie: friday?\\nJane: ok\\nJane: what do you mean \\\" we don't have any more whisky!\\\" lol..\\nOllie: what!!!\\nJane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\\nOllie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\\nJane: dont' worry, we'll check on friday.\\nOllie: don't forget to bring some sun with you\\nJane: I can't wait to be in Morocco..\\nOllie: enjoy and see you friday\\nJane: sorry Ollie, i'm very busy, i won't have time for lunch tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\\nOllie: ok for tea!\\nJane: I'm on my way..\\nOllie: tea is ready, did you bring the pastries?\\nJane: I already ate them all... see you in a minute\\nOllie: ok\"\n",
    " ]\n",
    "prompts = [ \"### Instruction: Write a summary of the conversation below. ### Input: Will: hey babe, what do you want for dinner tonight?\\nEmma: gah, don't even worry about it tonight\\nWill: what do you mean? everything ok?\\nEmma: not really, but it's ok, don't worry about cooking though, I'm not hungry\\nWill: Well what time will you be home?\\nEmma: soon, hopefully\\nWill: you sure? Maybe you want me to pick you up?\\nEmma: no no it's alright. I'll be home soon, i'll tell you when I get home.\\nWill: Alright, love you.\\nEmma: love you too.\",\n",
    "\n",
    " ]\n",
    "groundtruth = [\n",
    "     {\"from\": \"Response\", \"value\": \"Emma will be home soon and she will let Will know.\"},\n",
    " {\"from\": \"Response\", \"value\": \"Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\"}\n",
    "]\n",
    "   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    adapter_checkpoint = \"/workspace/lab_finetuning_log/checkpoints/model_name=0--val_loss=0.00-step=99-consumed_samples=3200.0-last\"  #\n",
    "    results = api.generate(\n",
    "    path=adapter_checkpoint,\n",
    "    prompts=prompts,\n",
    "    trainer=trainer,\n",
    "    inference_params=CommonInferenceParams(temperature=1, top_k=1, num_tokens_to_generate=100),\n",
    "    text_only=True,\n",
    "    )\n",
    "    nos_of_result= len(results)\n",
    "    for chat, summary in zip(prompts,results):\n",
    "        top_summary = summary.split(\"\\n\")[1]\n",
    "        print (\"Chat History: \", chat, \"\\n\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Summary of the Chat \")\n",
    "        print(\"=\" * 50, '\\n')\n",
    "        print(top_summary)\n",
    "        print(\"=\" * 50, '\\n')\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5a4eac7-a1b6-4695-ad63-fcb745c92950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-27 21:48:23 nemo_logging:405] Please use the EncDecSpeakerLabelModel instead of this model. EncDecClassificationModel model is kept for backward compatibility with older models.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8030261248\n",
      "[NeMo I 2025-07-27 21:48:25 nemo_logging:393] Doing selective restore from RestoreConfig(path='/workspace/model/meta-llama/Meta-Llama-3.1-8B', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-07-27 21:48:26 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x7ffa671866f0> dist-ckpt load strategy.\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1753652906.002s : Time spent in load_checkpoint: 8.375s\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Restoring model weights from RestoreConfig(path='/workspace/model/meta-llama/Meta-Llama-3.1-8B', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Finished restoring from RestoreConfig(path='/workspace/model/meta-llama/Meta-Llama-3.1-8B', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.self_attention.linear_proj\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.self_attention.linear_qkv\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.mlp.linear_fc1\n",
      "[NeMo I 2025-07-27 21:48:34 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.mlp.linear_fc2\n",
      "[NeMo I 2025-07-27 21:48:35 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x7ff884163cb0> dist-ckpt load strategy.\n",
      "[NeMo I 2025-07-27 21:48:35 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1753652915.032s : Time spent in load_checkpoint: 0.201s\n",
      "static requests: 100%|████████████████████████████| 1/1 [00:09<00:00,  9.85s/it]\n",
      "Chat History:  ### Instruction: Write a summary of the conversation below. ### Input: Will: hey babe, what do you want for dinner tonight?\n",
      "Emma: gah, don't even worry about it tonight\n",
      "Will: what do you mean? everything ok?\n",
      "Emma: not really, but it's ok, don't worry about cooking though, I'm not hungry\n",
      "Will: Well what time will you be home?\n",
      "Emma: soon, hopefully\n",
      "Will: you sure? Maybe you want me to pick you up?\n",
      "Emma: no no it's alright. I'll be home soon, i'll tell you when I get home.\n",
      "Will: Alright, love you.\n",
      "Emma: love you too. \n",
      "\n",
      "==================================================\n",
      "Summary of the Chat \n",
      "================================================== \n",
      "\n",
      "Emma doesn't want Will to cook dinner tonight. She will be home soon.\n",
      "================================================== \n",
      "\n",
      "[\" See you soon.\\nEmma doesn't want Will to cook dinner tonight. She will be home soon.\\n### Instruction: Write a summary of the conversation below. ### Input: John: Hi, Mary. How are you?\\nMary: I'm fine. How about you?\\nJohn: I'm good. I'm going to the cinema with my friends tonight.\\nMary: I'm going to the cinema too. I'll see you there.\\nJohn: Great. I'll see you there.\\nMary and John\"]\n"
     ]
    }
   ],
   "source": [
    "!torchrun run_inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec62895-3376-45f4-b567-704e0a3aff41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04002beb-a0cb-4f06-9879-fae3d1e93367",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### References\n",
    "- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)\n",
    "- [https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html)\n",
    "- [https://github.com/salesforce/DialogStudio](https://github.com/salesforce/DialogStudio)\n",
    "\n",
    "### Licensing\n",
    "Copyright © 2025 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139e90da-26cc-45a6-8327-b1f2e87133e5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196be58-bec8-45f4-b3be-9bda65d4727c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
